# Pipeline Configuration

pipeline:
  name: "production_rag_system"
  version: "1.0.0"
  description: "Production RAG system for technical documentation"

# Data ingestion
data:
  source_dir: "./docs"
  file_types: ["pdf", "md", "txt", "docx"]
  recursive: true
  exclude_patterns: ["archive", "old", "tmp"]
  
# Indexing configuration
indexing:
  index_type: "vector"
  chunk_size: 1024
  chunk_overlap: 200
  chunking_strategy: "sentence"
  embedding_model: "text-embedding-ada-002"
  
  # Storage backend
  storage:
    backend: "local"  # Options: local, pinecone, weaviate, chroma
    persist_dir: "./index"
    
# Retrieval configuration
retrieval:
  retriever_mode: "hybrid"
  top_k: 5
  similarity_threshold: 0.75
  enable_mmr: true
  mmr_diversity_bias: 0.3
  
  # Reranking
  enable_reranking: true
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  rerank_top_n: 3
  
# Generation configuration
generation:
  llm_model: "gpt-4"
  temperature: 0.1
  max_tokens: 500
  
  # Prompts
  system_prompt: |
    You are an expert technical assistant.
    Provide accurate, detailed answers based on the retrieved context.
    
  qa_prompt: |
    Context: {context}
    
    Question: {query}
    
    Provide a comprehensive answer:
  
  # Response settings
  response_mode: "compact"
  enable_streaming: false
  enable_citations: true
  
# Evaluation configuration
evaluation:
  enabled: true
  metrics:
    - "faithfulness"
    - "relevance"
    - "answer_correctness"
  test_queries_file: "test_queries.json"
  run_on_build: true
  
  # Thresholds
  thresholds:
    faithfulness: 0.80
    relevance: 0.75
    answer_correctness: 0.80
    
# Monitoring configuration
monitoring:
  enabled: true
  metrics:
    - "latency"
    - "token_usage"
    - "error_rate"
    - "query_volume"
  
  # Export settings
  export_to: "prometheus"
  prometheus_port: 9090
  
  # Alerting
  alerts:
    - metric: "latency"
      threshold: 2000  # ms
      action: "log"
    - metric: "error_rate"
      threshold: 0.05  # 5%
      action: "email"
      recipients: ["ops@example.com"]
      
# Performance tuning
performance:
  cache_enabled: true
  cache_ttl: 3600  # seconds
  batch_size: 32
  num_workers: 4
  timeout: 30  # seconds
  
# Deployment settings
deployment:
  environment: "production"  # development, staging, production
  port: 8000
  workers: 4
  log_level: "INFO"
  enable_cors: true
  allowed_origins: ["https://example.com"]
